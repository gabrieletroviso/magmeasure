{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyLensLib.piemd import piemd\n",
    "from pyLensLib.pointsrc import pointsrc\n",
    "from pyLensLib.sersic import *\n",
    "import numpy as np\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "from skimage import measure\n",
    "import shapely.geometry\n",
    "from pyLensLib.critcau import CriticalLine\n",
    "from shapely.ops import polygonize, unary_union\n",
    "import astropy.io.fits as pyfits\n",
    "from tqdm import tqdm\n",
    "from pyLensLib.deflector import deflector\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "from pyLensLib.observation import observation\n",
    "from pyLensLib.maputils import image_fit\n",
    "from scipy.ndimage import map_coordinates\n",
    "from astropy.wcs import WCS\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord, funcs\n",
    "from astropy.nddata import Cutout2D\n",
    "from skimage.transform import rescale\n",
    "from pyLensLib.maputils import image_fit, map_obj, contour_fit\n",
    "import pymupds\n",
    "\n",
    "# set up cosmology\n",
    "co = FlatLambdaCDM(H0=70.0, Om0=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(image, newpix):\n",
    "    image_rescaled = skimage.transform.rescale(image, newpix/image.shape[0])\n",
    "    return image_rescaled\n",
    "\n",
    "def cutout_image(image, coords, fov=200.0):\n",
    "    \n",
    "    hdul=image\n",
    "    w = WCS(image)\n",
    "    image_ = hdul.data\n",
    "    size = u.Quantity((fov,fov), u.arcsec)\n",
    "    position_ = SkyCoord(coords, frame = 'fk5', unit = 'deg')\n",
    "    cutout_ = Cutout2D(image_, position_, size, wcs=w)\n",
    "    w_up = cutout_.wcs\n",
    "    header_ = w_up.to_header()\n",
    "    hdu_hst = pyfits.PrimaryHDU(cutout_.data, header=header_)\n",
    "    hdu_hst = formatNewHeader(hdu_hst, fov)\n",
    "    \n",
    "    return hdu_hst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatHeaderForCut(a_x, a_y, pix):\n",
    "    \n",
    "    a_x.header[\"CRPIX1\"]  =  (a_x.shape[0]//2, \"Pixel coordinate of reference point\")            \n",
    "    a_x.header[\"CRPIX2\"]  =  (a_x.shape[0]//2, \"Pixel coordinate of reference point\")  \n",
    "    a_x.header[\"CRVAL1\"]  =  (0.0, \"[deg] Coordinate value at reference point\")      \n",
    "    a_x.header[\"CRVAL2\"]  =  (0.0, \"[deg] Coordinate value at reference point\")\n",
    "    a_x.header[\"CDELT1\"]  =  ( pix , \"[deg] Coordinate increment at reference point\")  \n",
    "    a_x.header[\"CDELT2\"]  =  ( pix , \"[deg] Coordinate increment at reference point\")  \n",
    "    a_x.header[\"CUNIT1\"]  =  (\"deg\", \"Units of coordinate increment and value\")        \n",
    "    a_x.header[\"CUNIT2\"]  =  (\"deg\", \"Units of coordinate increment and value\")        \n",
    "    a_x.header[\"CTYPE1\"]  =  (\"RA---TAN\", \"Right ascension, gnomonic projection\")          \n",
    "    a_x.header[\"CTYPE2\"]  =  (\"DEC--TAN\", \"Declination, gnomonic projection\") \n",
    "    \n",
    "    \n",
    "    a_y.header[\"CRPIX1\"]  =  (a_y.shape[0]//2, \"Pixel coordinate of reference point\")            \n",
    "    a_y.header[\"CRPIX2\"]  =  (a_y.shape[0]//2, \"Pixel coordinate of reference point\")  \n",
    "    a_y.header[\"CRVAL1\"]  =  (0.0, \"[deg] Coordinate value at reference point\")      \n",
    "    a_y.header[\"CRVAL2\"]  =  (0.0, \"[deg] Coordinate value at reference point\")\n",
    "    a_y.header[\"CDELT1\"]  =  ( pix , \"[deg] Coordinate increment at reference point\")  \n",
    "    a_y.header[\"CDELT2\"]  =  ( pix , \"[deg] Coordinate increment at reference point\")  \n",
    "    a_y.header[\"CUNIT1\"]  =  (\"deg\", \"Units of coordinate increment and value\")        \n",
    "    a_y.header[\"CUNIT2\"]  =  (\"deg\", \"Units of coordinate increment and value\")        \n",
    "    a_y.header[\"CTYPE1\"]  =  (\"RA---TAN\", \"Right ascension, gnomonic projection\")          \n",
    "    a_y.header[\"CTYPE2\"]  =  (\"DEC--TAN\", \"Declination, gnomonic projection\")\n",
    "    \n",
    "    a_x.header[\"RADESYS\"] = \"FK5\"\n",
    "    a_y.header[\"RADESYS\"] = \"FK5\"\n",
    "    \n",
    "    return a_x, a_y\n",
    "\n",
    "def formatNewHeader(hdu, fov):\n",
    "   \n",
    "    hdu.header[\"XMAX\"] = (fov/2, \"xMax arcsec\")\n",
    "    hdu.header[\"XMIN\"] = (-fov/2, \"xMin arcsec\")\n",
    "    hdu.header[\"YMAX\"] = (fov/2, \"yMax arcsec\")\n",
    "    hdu.header[\"YMIN\"] = (-fov/2, \"yMin arcsec\")\n",
    "    hdu.header[\"CRPIX1\"] = (hdu.shape[0]//2, \"Pixel coordinate of reference point\")\n",
    "    hdu.header[\"CRPIX2\"] = (hdu.shape[1]//2, \"Pixel coordinate of reference point\")\n",
    "    \n",
    "    del hdu.header[\"CRVAL1\"]\n",
    "    del hdu.header[\"CRVAL2\"]\n",
    "    \n",
    "    return hdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatHeaderDef(newAng, oldAng):\n",
    "    \n",
    "    hdu = pyfits.PrimaryHDU(newAng)\n",
    "    hdu.header[\"XMIN\"] = (oldAng.header[\"XMIN\"], \"xMin arcsec\")\n",
    "    hdu.header[\"XMAX\"] = (oldAng.header[\"XMAX\"], \"xMax arcsec\")\n",
    "    hdu.header[\"YMIN\"] = (oldAng.header[\"YMIN\"], \"yMin arcsec\")\n",
    "    hdu.header[\"YMAX\"] = (oldAng.header[\"YMAX\"], \"yMax arcsec\")\n",
    "    \n",
    "    return hdu\n",
    "\n",
    "def selImage(file_sim, mu_image, lens, cnt):\n",
    "    \n",
    "    x, y = lens.getCritPoints(cnt, pixel_units=True)\n",
    "    xmin, xmax, ymin, ymax = np.min(x), np.max(x), np.min(y), np.max(y)\n",
    "    lim = max(int(round(xmax-xmin)), int(round(ymax-ymin)))\n",
    "    xc, yc = (xmax-xmin)/2+xmin, (ymax-ymin)/2+ymin\n",
    "\n",
    "    cutSim = file_sim[int(round(yc-lim/2-1)):int(round(yc+lim/2+1)),int(round(xc-lim/2-1)):int(round(xc+lim/2+1))]\n",
    "    cutMap = mu_image[int(round(yc-lim/2-1)):int(round(yc+lim/2+1)),int(round(xc-lim/2-1)):int(round(xc+lim/2+1))]\n",
    "    \n",
    "    return cutSim, cutMap, xc, yc\n",
    "\n",
    "def check(cnt, lens, point):\n",
    "    \n",
    "    x, y = lens.getCritPoints(cnt, pixel_units=True)\n",
    "    xmin, xmax, ymin, ymax = np.min(x), np.max(x), np.min(y), np.max(y)\n",
    "    i = []\n",
    "    for p in point:\n",
    "        if p[0] >= xmin and p[0] <=xmax and p[1] >= ymin and p[1] <= ymax:\n",
    "            i.append([p[0],p[1]])\n",
    "    i = np.array(i)\n",
    "    \n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_images(se, noise_level, mu, mus, mask_unlensed, s, sFoldImages, xpos, ypos, pix, sz, model, lens, cntList, point):\n",
    "    \n",
    "    for i in range(len(cntList)):\n",
    "        \n",
    "        cutSim, cutMap, xc, yc = selImage(se.image, mu, lens, cntList[i])\n",
    "        \n",
    "        ai = image_fit(cutSim, ith= noise_level)\n",
    "        cen = ai.centroid()\n",
    "            \n",
    "        #mu_point = cutMap[int(cen[1]),int(cen[0])]\n",
    "        mask_lensed = cutSim > noise_level\n",
    "        \n",
    "        #ff, aa = plt.subplots(1,2,figsize=(10,10))\n",
    "        #aa[0].imshow(cutSim, origin=\"lower\", vmin=10e-6, vmax=10e-2, cmap=plt.cm.bone)\n",
    "        #aa[1].imshow(cutMap, origin=\"lower\", cmap=plt.cm.cubehelix)\n",
    "        \n",
    "        ratio_area = mask_lensed.sum()/mask_unlensed.sum()\n",
    "        ratio_flux = np.sum(cutSim*mask_lensed)/np.sum(se.image_unlensed*mask_unlensed)\n",
    "        mean_map = np.mean(cutMap[mask_lensed])\n",
    "        median_map = np.median(cutMap[mask_lensed])\n",
    "        weAvarage_map = np.average(cutMap[mask_lensed], weights=cutSim[mask_lensed])\n",
    "        #point_map = mu_point\n",
    "        \n",
    "        mu_flux = np.sum((mus * se.image_unlensed) * mask_unlensed)\n",
    "        flux = np.sum(se.image_unlensed * mask_unlensed)\n",
    "        mu_true = mu_flux / flux\n",
    "        \n",
    "        #aa[0].plot(cen[0], cen[1], \"o\", markersize=1, color=\"red\")\n",
    "        #aa[1].plot(cen[0], cen[1], \"o\", markersize=1, color=\"red\")\n",
    "        \n",
    "        pntInImage = check(cntList[i], lens, point)\n",
    "        if len(pntInImage)==0:\n",
    "            xi, yi = xc*pix-sz/2.0, yc*pix-sz/2.0\n",
    "            point_map = cutMap[int(cen[1]),int(cen[0])]\n",
    "            \n",
    "            s_entry = {'x': xpos,'y': ypos,\n",
    "                       'xi': xi,'yi': yi,\n",
    "                       'mus_true': mu_true, 'area_ratio': ratio_area,\n",
    "                       'flux_ratio': ratio_flux, model+'_mean_mu': mean_map,\n",
    "                       model+'_median_mu':  median_map, model+'_wfl_mu':weAvarage_map, model+'_mu_point': point_map}\n",
    "            s.append(s_entry)\n",
    "        else:\n",
    "            for n in pntInImage:\n",
    "                xi, yi = n[0]*pix-sz/2.0, n[1]*pix-sz/2.0\n",
    "                point_map = mu[int(n[1]),int(n[0])]\n",
    "            \n",
    "                s_entry = {'x': xpos,'y': ypos,\n",
    "                           'xi': xi,'yi': yi,\n",
    "                           'mus_true': mu_true, 'area_ratio': ratio_area,\n",
    "                           'flux_ratio': ratio_flux, model+'_mean_mu': mean_map,\n",
    "                           model+'_median_mu':  median_map, model+'_wfl_mu':weAvarage_map, model+'_mu_point': point_map}\n",
    "            \n",
    "                s.append(s_entry)\n",
    "        \n",
    "        if len(cntList) == 3 and len(point) == 3:\n",
    "            for n in pntInImage:\n",
    "                xi, yi = n[0]*pix-sz/2.0, n[1]*pix-sz/2.0\n",
    "                point_map = mu[int(n[1]),int(n[0])]\n",
    "                s_fold_entry = {'x': xpos,'y': ypos,\n",
    "                                'xi': xi,'yi': yi,\n",
    "                                'mus_true': mu_true, 'area_ratio': ratio_area,\n",
    "                                'flux_ratio': ratio_flux, model+'_mean_mu': mean_map,\n",
    "                                model+'_median_mu':  median_map, model+'_wfl_mu':weAvarage_map, model+'_mu_point': point_map, \n",
    "                                'flux': np.sum(cutSim*mask_lensed)} \n",
    "                sFoldImages.append(s_fold_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(contours):\n",
    "    c_all = []\n",
    "    j = 0\n",
    "    for contour in contours:\n",
    "        contour[:, 0], contour[:, 1] = contour[:, 1].copy(), contour[:, 0].copy()\n",
    "        ls = shapely.geometry.LineString(contour)\n",
    "        lr = shapely.geometry.LineString(ls.coords[:] + ls.coords[0:1])\n",
    "        mls = unary_union(lr)\n",
    "        mp = shapely.geometry.MultiPolygon(list(polygonize(mls)))\n",
    "        c = CriticalLine(j, mp)\n",
    "        c.setPoints(contour)\n",
    "        A = 0.0\n",
    "        for g in range(len(mp)):\n",
    "            A += mp[g].area\n",
    "        c.setArea(A)\n",
    "        c_all.append(c)\n",
    "        j += 1\n",
    "    c_sorted = sorted(c_all, key=lambda x: x.getArea(), reverse=True)\n",
    "    return (c_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zl, zsnorm, zslist = 0.5, 2, [1, 2, 4, 6]\n",
    "\n",
    "model = [] #name of magnification map models, if these name is\n",
    "           #present in .fits magnification file name \n",
    "\n",
    "for zs in zslist:\n",
    "    mappa_ = [pyfits.open(\"\")[0]] #magnification map\n",
    "\n",
    "    fov = []\n",
    "    for k in range(len(mappa_)):\n",
    "        f = mappa_[k].header[\"CDELT2\"]*3600*(mappa_[k].header[\"NAXIS1\"]-1)\n",
    "        fov.append(f)\n",
    "    fovCut = round(min(fov),2)\n",
    "\n",
    "    ang_ = pyfits.open(\"\") #deflection angle map\n",
    "    angx_, angy_ = ang_[0], ang_[1]\n",
    "    \n",
    "    pix_ = ((angx_.header['XMAX']-angx_.header['XMIN'])/angx_.header['NAXIS1'])/3600\n",
    "    angx_, angy_ = formatHeaderForCut(angx_, angy_, pix_)\n",
    "    angx_, angy_ = cutout_image(angx_, [\"0 0\"], fov=fovCut), cutout_image(angy_, [\"0 0\"], fov=fovCut)\n",
    "    angx, angy = rescale(angx_.data, 4080), rescale(angy_.data, 4080)\n",
    "    angx = formatHeaderDef(angx, angx_)\n",
    "\n",
    "    pix = ((angx.header['XMAX']-angx.header['XMIN'])/angx.header['NAXIS1'])\n",
    "    npix = angx.shape[0]\n",
    "    sz = pix*(npix)\n",
    "\n",
    "    kwargs = {\n",
    "        'zl': zl,\n",
    "        'zs': zsnorm\n",
    "    }\n",
    "\n",
    "    lens = deflector(co=co, angx=angx.data, angy=angy.data, usePotential=False, **kwargs)\n",
    "    theta = np.linspace(-sz/2,sz/2,npix)\n",
    "    lens.setGrid(theta)\n",
    "    lens.change_redshift(zs)\n",
    "    tEin = lens.thetaE()\n",
    "    detA = (1.0 - lens.ka) ** 2 - (lens.g1 ** 2 + lens.g2 ** 2)\n",
    "    mu=np.abs(1.0/detA)\n",
    "\n",
    "    ct, cr = lens.tancl(), lens.radcl()\n",
    "    caut, caur = lens.getCaustics(ct), lens.getCaustics(cr)\n",
    "    \n",
    "    print(\"Source's redshift: \"+str(zs)+\" - - - -\")\n",
    "    print(\"Shape: %5i px\" % angx.shape[0])\n",
    "    print(\"Fov: %5.2f arcsec\" % sz)\n",
    "    print(\"Pixel: %5.2f arcsec\" % pix)\n",
    "    print(\"Einstein's radius: %5.2f arcsec\" % tEin)\n",
    "    print(\"- - - - - - - - - - - - - - - - - - - \")\n",
    "    \n",
    "    angx4pntSrc, angy4pntSrc = rescale(angx.data, 2040), rescale(angy.data, 2040)\n",
    "    pix4pntSrc = 4080/2040*pix\n",
    "    npix4pntSrc = 2040\n",
    "    lens4pntSrc = deflector(co=co, angx=angx4pntSrc, angy=angy4pntSrc, usePotential=False, **kwargs)\n",
    "    theta4pntSrc = np.linspace(-sz/2,sz/2,npix4pntSrc)\n",
    "    lens4pntSrc.setGrid(theta4pntSrc)\n",
    "    lens4pntSrc.change_redshift(zs)\n",
    "    \n",
    "    mappa = [rescale(cutout_image(mappa_[0], [\"0 0\"], fov=fovCut).data, 4080),\n",
    "             rescale(cutout_image(mappa_[1], [\"0 0\"], fov=fovCut).data, 4080),\n",
    "             rescale(cutout_image(mappa_[2], [\"0 0\"], fov=fovCut).data, 4080)]\n",
    "    \n",
    "    mag_source, mag_lens, mag_sky = 22.0, 18.0, 22.5\n",
    "    zp = 23.9\n",
    "    \n",
    "    y1 = lens.theta1 - lens.a1 + 2 * lens.pixel_scale\n",
    "    y2 = lens.theta2 - lens.a2 + 2 * lens.pixel_scale\n",
    "    mus = pymupds.mupds_triangle(y1 - lens.theta1.min(), y2 - lens.theta2.min(), lens.pixel_scale, detA, nray=len(theta))\n",
    "\n",
    "    ob = observation(size=sz, Npix=npix, zp=zp, texp=565 * 4, bkg=mag_sky)\n",
    "    fl_gal, fl_lens, sky_counts = ob.mag2counts(mag_source), ob.mag2counts(mag_lens), ob.bkg_counts\n",
    "    # define a grid of sources\n",
    "    fov_zs = int(tEin)\n",
    "    thetasx = np.linspace(-7-fov_zs/2.0,-7+fov_zs/2.0,50)\n",
    "    thetasy = np.linspace(-fov_zs/2.0,+fov_zs/2.0,50)\n",
    "    thetas1, thetas2 = np.meshgrid(thetasx,thetasy)\n",
    "\n",
    "    thetas1=thetas1.flatten()\n",
    "    thetas2=thetas2.flatten()\n",
    "            \n",
    "    s0, s1, s2 = [], [], []\n",
    "    s0F, s1F, s2F = [], [], []\n",
    "    listaS, listaSF = [s0,s1,s2], [s0F, s1F, s2F]\n",
    "    re, sersInd = 0.7, 4.0 #capire come fare sorgenti piÃ¹ estese\n",
    "    \n",
    "    #for i in tqdm(range(0,1)):\n",
    "    for i in tqdm(range(0,2300)):\n",
    "    #for i in tqdm(range(len(thetas1))):\n",
    "    \n",
    "        kwargs_source_light = {\n",
    "            'n': sersInd,  # sersic index\n",
    "            're': re,  # effective radius\n",
    "            'q': 1.0,  # axis ratio\n",
    "            'pa': np.pi / 4.,  # position angle\n",
    "            'ys1': thetas1[i],  # 3.8,  # position x (on the source plane)\n",
    "            'ys2': thetas2[i],  # 3.8,  # position y (on the source plane)\n",
    "            'flux': fl_gal,  # flux of the source (in counts/s)\n",
    "            'zs': zs\n",
    "        }\n",
    "        \n",
    "        kwargs_source_light_4pntSrc = {\n",
    "            'ys1': thetas1[i],   \n",
    "            'ys2': thetas2[i],   \n",
    "            'flux': fl_gal,  \n",
    "            'zs': zs\n",
    "        }\n",
    "\n",
    "        se = sersic(size=sz, Npix=npix, gl=lens, save_unlensed=True, **kwargs_source_light)\n",
    "        pntSrc = pointsrc(size=sz, Npix=npix4pntSrc, gl=lens4pntSrc, **kwargs_source_light_4pntSrc)\n",
    "        imgPosition = pntSrc.find_images()\n",
    "        noise = ob.makeNoise(se.image)\n",
    "        \n",
    "        if np.size(imgPosition)!=3:\n",
    "            pntPos = []\n",
    "            for j in range(len(imgPosition)):\n",
    "                pntPos.append([imgPosition[0][j], imgPosition[1][j]])\n",
    "            pntPos = np.array(pntPos)\n",
    "            pntPos = (pntPos/pix4pntSrc+2040/2)*2\n",
    "        else:\n",
    "            imgPosition = np.array(imgPosition)\n",
    "            imgPosition = (imgPosition/pix4pntSrc+2040/2)*2\n",
    "            pntPos = [[imgPosition[0][0], imgPosition[1][0]]]\n",
    "            pntPos = np.array(pntPos)\n",
    "        \n",
    "        #SNR = 1.0\n",
    "        SNR = 5.0\n",
    "        #SNR = 10.0\n",
    "        noise_level = 0.5 * (1.0 + np.sqrt(1.0 + 4.0 * ob.bkg_counts * ob.texp)) / ob.texp * SNR\n",
    "\n",
    "        cnt = se.image_contours(level=noise_level)\n",
    "        contours___ = measure.find_contours(se.image_unlensed, noise_level)\n",
    "        cnt_source = sort_contours(contours___)\n",
    "    \n",
    "        mask_lensed = se.image > noise_level\n",
    "        mask_unlensed = se.image_unlensed > noise_level\n",
    "    \n",
    "        if len(cnt)!=1:\n",
    "            for j in range(len(model)):\n",
    "                multiple_images(se=se, noise_level=noise_level, mu=mappa[j], mus=mus.T, mask_unlensed=mask_unlensed, s=listaS[j], sFoldImages=listaSF[j], xpos=thetas1[i], ypos=thetas2[i], pix=pix, sz=sz, model=model[j], lens=lens, cntList=cnt, point=pntPos)\n",
    "                continue\n",
    "            continue\n",
    "\n",
    "        ai = image_fit(se.image, ith=noise_level)\n",
    "        cen = ai.centroid()\n",
    "\n",
    "        area_ratio = mask_lensed.sum() / mask_unlensed.sum()\n",
    "        flux_ratio = np.sum(se.image * mask_lensed) / np.sum(se.image_unlensed * mask_unlensed)\n",
    "    \n",
    "        mu_flux = np.sum((mus.T * se.image_unlensed) * mask_unlensed)\n",
    "        flux = np.sum(se.image_unlensed * mask_unlensed)\n",
    "        mu_true = mu_flux / flux\n",
    "                        \n",
    "        for k in range(len(model)):\n",
    "            mean_mu, median_mu, wfl_mu, mu_point = np.mean(mappa[k][mask_lensed]), np.median(mappa[k][mask_lensed]), np.average(mappa[k][mask_lensed], weights=se.image[mask_lensed]), mappa[k][int(pntPos[0,1]), int(pntPos[0,0])]\n",
    "            s_entry = {'x': thetas1[i],'y': thetas2[i],\n",
    "                       'xi':cen[0]*pix-sz/2.0,'yi':cen[1]*pix-sz/2.,\n",
    "                       'mus_true': mu_true, 'area_ratio': area_ratio,\n",
    "                       'flux_ratio': flux_ratio, model[k]+'_mean_mu': mean_mu,\n",
    "                       model[k]+'_median_mu': median_mu, model[k]+'_wfl_mu': wfl_mu, model[k]+'_mu_point': mu_point}\n",
    "            listaS[k].append(s_entry)\n",
    "        \n",
    "\n",
    "    for m in range(len(model)):\n",
    "        sdf = pd.DataFrame(listaS[m])\n",
    "        sdfF = pd.DataFrame(listaSF[m])\n",
    "        sdf.to_csv(\"\")\n",
    "        sdfF.to_csv(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
